{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fake_review_generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "H6BZFhaiyrSH",
        "colab_type": "code",
        "outputId": "f7305d97-0e97-4e80-fbec-39dacaf2078c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "# This is code to download and install pytorch\n",
        "import os\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if os.path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch\n",
        "print('Version', torch.__version__)\n",
        "print('CUDA enabled:', torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Version 0.4.1\n",
            "CUDA enabled: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-3nAtMGTFHC7",
        "colab_type": "code",
        "outputId": "f90cf461-e16a-42c9-9e69-77c8e2ec421d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "!ls /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4pbIvoCW-mWO",
        "colab_type": "code",
        "outputId": "4d5c2af5-fc2e-4dda-9396-b7fdb9b7172a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/fake_review_generator/'\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    os.makedirs(BASE_PATH)\n",
        "DATA_PATH = BASE_PATH + 'fake_review_generator/'\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    os.makedirs(DATA_PATH)\n",
        "\n",
        "!pwd\n",
        "!ls\n",
        "    \n",
        "os.chdir(BASE_PATH)\n",
        "if not os.path.exists(BASE_PATH + 'pt_util.py'):\n",
        "  !wget https://vinitha910.github.io/pt_util.py\n",
        "    \n",
        "os.chdir(DATA_PATH)\n",
        "if not os.path.exists(DATA_PATH + 'processed_data/Office_Products.csv'):\n",
        "    !wget https://vinitha910.github.io/office_products_review.tar.gz\n",
        "    !tar -xvf office_products_review.tar.gz\n",
        "    !rm office_products_review.tar.gz\n",
        "os.chdir('/content')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hDSS1nUKzWHW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "import pickle\n",
        "import re\n",
        "sys.path.append(BASE_PATH)\n",
        "import pt_util\n",
        "import string\n",
        "from math import log\n",
        "from math import exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TyTVS7ILDK-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_data(data_path, name):\n",
        "    with open(data_path) as f:\n",
        "        # This reads all the data from the file, but does not do any processing on it.\n",
        "        data = f.read()\n",
        "        data = data.replace(string.whitespace, \" \")\n",
        "        data = data.replace(\"\\n\", \" \")\n",
        "        data = data.replace(\"\\t\", \" \")\n",
        "        data = data.replace(\"\\x1f\", \"\")\n",
        "        data = data.replace(\"\\x08\", \"\")\n",
        "        data = data.replace(\"\\x1c\", \"\")\n",
        "        \n",
        "    tokens = []\n",
        "    data = data.split()\n",
        "    data = data[int(0.1*len(data) + 113):int(0.2*len(data) + 113)]\n",
        "    for word in data:\n",
        "      tokens.append(word)\n",
        "    tokens = np.array(tokens)    \n",
        "    unique_tokens = np.unique(tokens)\n",
        "\n",
        "    voc2ind = {}\n",
        "    for i in range(len(unique_tokens)):\n",
        "      voc2ind[unique_tokens[i]] = i\n",
        "    \n",
        "    data_tokens = []\n",
        "    for word in data:\n",
        "        data_tokens.append(voc2ind[word])\n",
        "\n",
        "    ind2voc = {val: key for key, val in voc2ind.items()}\n",
        "\n",
        "    train_text = data_tokens[:int(0.8*len(data_tokens))]\n",
        "    test_text = data_tokens[int(0.8*len(data_tokens)):]\n",
        "\n",
        "    pickle.dump({'tokens': train_text, 'ind2voc': ind2voc, 'voc2ind':voc2ind}, open(DATA_PATH + name + '_chars_train.pkl', 'wb'))\n",
        "    pickle.dump({'tokens': test_text, 'ind2voc': ind2voc, 'voc2ind':voc2ind}, open(DATA_PATH + name + '_chars_test.pkl', 'wb'))\n",
        "    \n",
        "prepare_data(DATA_PATH + 'processed_data/Office_Products.csv', 'office_products')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jSZfVl0fFrJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self, data_file):\n",
        "        with open(data_file, 'rb') as data_file:\n",
        "            dataset = pickle.load(data_file)\n",
        "        self.ind2voc = dataset['ind2voc']\n",
        "        self.voc2ind = dataset['voc2ind']\n",
        "\n",
        "    # Returns a string representation of the tokens.\n",
        "    def array_to_words(self, arr):\n",
        "        return \" \".join([self.ind2voc[int(ind)] for ind in arr])\n",
        "\n",
        "    # Returns a torch tensor representing each token in words.\n",
        "    def words_to_array(self, words):\n",
        "        return torch.LongTensor([self.voc2ind[word] for word in words])\n",
        "\n",
        "    # Returns the size of the vocabulary.\n",
        "    def __len__(self):\n",
        "        return len(self.voc2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "psPk8OCuGq5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ReviewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_file, sequence_length, batch_size):\n",
        "        super(ReviewsDataset, self).__init__()\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "        self.vocab = Vocabulary(data_file)\n",
        "\n",
        "        with open(data_file, 'rb') as data_pkl:\n",
        "            dataset = pickle.load(data_pkl)\n",
        "\n",
        "        self.tokens = dataset['tokens']\n",
        "        remainder = len(self.tokens) % (self.batch_size*self.sequence_length)\n",
        "        num_tokens = len(self.tokens) - remainder\n",
        "        self.tokens = self.tokens[:num_tokens]\n",
        "\n",
        "        assert len(self.tokens) % batch_size == 0\n",
        "  \n",
        "        incr = len(self.tokens)/self.batch_size\n",
        "        index_range = len(self.tokens)/self.batch_size\n",
        "        data_start_idx = 0\n",
        "        label_start_idx = 1\n",
        "        data_end_idx = data_start_idx + self.sequence_length\n",
        "        label_end_idx = label_start_idx + self.sequence_length\n",
        "        batch = 0 \n",
        "        data = [[]]\n",
        "        labels = [[]]\n",
        "\n",
        "        while label_start_idx < len(self.tokens):\n",
        "            data[batch].append(self.tokens[int(data_start_idx):int(data_end_idx)])\n",
        "            labels[batch].append(self.tokens[int(label_start_idx):int(label_end_idx)])\n",
        "\n",
        "            if label_end_idx == index_range:\n",
        "                data.append([])\n",
        "                labels.append([])\n",
        "                data_start_idx = data_end_idx + 1\n",
        "                label_start_idx = label_end_idx + 1\n",
        "                data_end_idx = data_start_idx + self.sequence_length\n",
        "                label_end_idx = label_start_idx + self.sequence_length\n",
        "                index_range += incr\n",
        "                batch += 1\n",
        "\n",
        "            else:\n",
        "                data_start_idx += self.sequence_length\n",
        "                label_start_idx += self.sequence_length\n",
        "\n",
        "                data_end_idx += self.sequence_length\n",
        "                if data_end_idx > index_range - 1:\n",
        "                    data_end_idx = index_range - 1;\n",
        "\n",
        "                label_end_idx += self.sequence_length\n",
        "                if label_end_idx > index_range:\n",
        "                    label_end_idx = index_range\n",
        "        \n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        for b in range(len(data[0])):\n",
        "            self.data.append([])\n",
        "            self.labels.append([])\n",
        "            for d in range(len(data)):\n",
        "                if b < len(data[d]):\n",
        "                    self.data[-1].append(data[d][b])\n",
        "                    self.labels[-1].append(labels[d][b])\n",
        "\n",
        "        if len(self.data[-1][0]) < self.sequence_length:\n",
        "            self.data.pop()\n",
        "            self.labels.pop()\n",
        "            \n",
        "    def __len__(self):\n",
        "        sequences = []\n",
        "        for batch in self.data:\n",
        "            for sequence in batch:\n",
        "                sequences.append(sequence)\n",
        "        return len((np.array(sequences)))\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        col = int(idx % self.batch_size)\n",
        "        row = int(idx / self.batch_size)\n",
        "\n",
        "        if row >= len(self.data) or col >= len(self.data[row]):\n",
        "            print(\"ReviewsDataset index out of bounds\")\n",
        "            \n",
        "        item_data = torch.LongTensor(self.data[row][col])\n",
        "        item_label = torch.LongTensor(self.labels[row][col])\n",
        "        \n",
        "        return item_data, item_label\n",
        "\n",
        "    def vocab_size(self):\n",
        "        return len(self.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWn1eU7cNv1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, feature_size, batch_size, sequence_length):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embed_size\n",
        "        self.feature_size = feature_size\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder = nn.Embedding(self.vocab_size, embed_size)\n",
        "        self.fully_connected = nn.Linear(self.feature_size*sequence_length, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        self.best_accuracy = -1\n",
        "        \n",
        "    def forward(self, x, hidden=None):\n",
        "        # Embed word ids to vectors\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(-1,  x.size()[1]*x.size()[2]) \n",
        "        x = self.fully_connected(x)\n",
        "        x = self.sig(x)\n",
        "        return x\n",
        "      \n",
        "    def loss(self, prediction, label, reduction='elementwise_mean'):\n",
        "        loss_val = F.binary_cross_entropy(prediction, label, reduction=reduction)\n",
        "        return loss_val\n",
        "      \n",
        "    # Saves the current model\n",
        "    def save_model(self, file_path, num_to_keep=1):\n",
        "        pt_util.save(self, file_path, num_to_keep)\n",
        "\n",
        "    # Saves the best model so far\n",
        "    def save_best_model(self, accuracy, file_path, num_to_keep=1):\n",
        "        if accuracy > self.best_accuracy:\n",
        "            self.save_model(file_path, num_to_keep)\n",
        "            self.best_accuracy = accuracy\n",
        "\n",
        "    def load_model(self, file_path):\n",
        "        pt_util.restore(self, file_path)\n",
        "\n",
        "    def load_last_model(self, dir_path):\n",
        "        return pt_util.restore_latest(self, dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S1Z-xaA_HeJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, feature_size, num_layers):\n",
        "        super(Generator, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_layers = num_layers\n",
        "        self.encoder = nn.Embedding(self.vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, feature_size, num_layers, batch_first=True)\n",
        "        self.decoder = nn.Linear(feature_size, self.vocab_size)\n",
        "        \n",
        "        self.decoder.weight = self.encoder.weight\n",
        "        self.decoder.bias.data.zero_()\n",
        "        \n",
        "        self.best_accuracy = -1\n",
        "        \n",
        "    def forward(self, x, hidden=None):\n",
        "        # Embed word ids to vectors\n",
        "        x = self.encoder(x)\n",
        "         \n",
        "        # Forward propagate LSTM\n",
        "        output, (hidden, c) = self.lstm(x, hidden)\n",
        "        \n",
        "        # Reshape output to (batch_size*sequence_length, feature_size)\n",
        "        output = output.reshape(output.size(0)*output.size(1), output.size(2))\n",
        "        \n",
        "        # Decode hidden states of all time steps\n",
        "        output = self.decoder(output)\n",
        "        return output, (hidden, c)\n",
        "      \n",
        "    # This defines the function that gives a probability distribution and implements the temperature computation.\n",
        "    def inference(self, x, hidden_state=None, temperature=1.5):\n",
        "        x = x.view(-1, 1)\n",
        "        x, hidden_state = self.forward(x, hidden_state)\n",
        "        x = x.view(1, -1)\n",
        "        x = x / max(temperature, 1e-20)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x, hidden_state\n",
        "      \n",
        "    def loss(self, prediction, label, reduction='elementwise_mean'):\n",
        "        loss_val = F.cross_entropy(prediction.view(-1, self.vocab_size), label.view(-1), reduction=reduction)\n",
        "        return loss_val\n",
        "      \n",
        "    # Saves the current model\n",
        "    def save_model(self, file_path, num_to_keep=1):\n",
        "        pt_util.save(self, file_path, num_to_keep)\n",
        "\n",
        "    # Saves the best model so far\n",
        "    def save_best_model(self, accuracy, file_path, num_to_keep=1):\n",
        "        if accuracy > self.best_accuracy:\n",
        "            self.save_model(file_path, num_to_keep)\n",
        "            self.best_accuracy = accuracy\n",
        "\n",
        "    def load_model(self, file_path):\n",
        "        pt_util.restore(self, file_path)\n",
        "\n",
        "    def load_last_model(self, dir_path):\n",
        "        return pt_util.restore_latest(self, dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oc35IBYHWKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "BEAM_WIDTH = 10\n",
        "\n",
        "def generate_language(model, device, seed_words, sequence_length, vocab, beam_width=BEAM_WIDTH, use_indices=False, sampling_strategy='sample'):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():  \n",
        "        seed_words_arr = vocab.words_to_array(seed_words)\n",
        "        \n",
        "        # Computes the initial hidden state from the prompt (seed words).\n",
        "        hidden = None\n",
        "        for ind in seed_words_arr:\n",
        "            data = ind.to(device)\n",
        "            output, hidden = model.inference(data, hidden)\n",
        "\n",
        "        outputs = []\n",
        "        # Initializes the beam list.\n",
        "        beams = [([], output, hidden, 0)]\n",
        "        \n",
        "        for ii in range(sequence_length):\n",
        "            if sampling_strategy == 'sample':\n",
        "                probabilities = output.exp()\n",
        "                val = torch.multinomial(probabilities, num_samples=1)\n",
        "                outputs += [val[0]]\n",
        "                output, hidden = model.inference(val[0], hidden)\n",
        "                \n",
        "            elif sampling_strategy == 'beam':\n",
        "                all_beams = list()\n",
        "                # For each beam in the beam list\n",
        "                for i in range(len(beams)):\n",
        "                    sequence, output, hidden, score = beams[i]\n",
        "\n",
        "                    if (len(sequence) > 0):\n",
        "                        # Compute the next distribution over the output space for that state\n",
        "                        output, hidden = model.inference(sequence[-1], hidden)\n",
        "\n",
        "                    # Sample from the distribution    \n",
        "                    samples = torch.multinomial(output, BEAM_WIDTH)\n",
        "\n",
        "                    # For each sample\n",
        "                    for sample in samples[0]:\n",
        "                        # Compute its score and Record its hidden state and chosen value\n",
        "                        beam = (sequence + [sample], output, hidden, score + log(output[0][sample]))\n",
        "                        # Add all the samples to the new beam list\n",
        "                        all_beams.append(beam)\n",
        "\n",
        "                # Rank the new beam list\n",
        "                ordered_beams = sorted(all_beams, key=lambda beam:beam[3], reverse=True)\n",
        "\n",
        "                # Throw out all but the top N beams\n",
        "                beams = ordered_beams[:5]\n",
        "\n",
        "                # Return the top beam's chosen values\n",
        "                outputs = beams[0][0]\n",
        "        \n",
        "        if not use_indices:\n",
        "            return vocab.array_to_words(seed_words_arr.tolist() + outputs)\n",
        "        else:\n",
        "            return seed_words_arr.tolist() + outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGpDwKPhKsR-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "def train(generator, discriminator, device, train_loader, lr, epoch, log_interval, vocab, batch_size, sequence_length):\n",
        "    losses = []\n",
        "    hidden = None\n",
        "    for batch_idx, (data, label) in enumerate(train_loader):\n",
        "        human_data, label = data.to(device), label.to(device)\n",
        "        # Separates the hidden state across batches. \n",
        "        # Otherwise the backward would try to go all the way to the beginning every time.\n",
        "        if hidden is not None:\n",
        "            hidden = repackage_hidden(hidden)\n",
        "        \n",
        "        human_labels = torch.ones(BATCH_SIZE, 1).to(device)\n",
        "        machine_labels = torch.zeros(BATCH_SIZE, 1).to(device)\n",
        "        \n",
        "        # Discriminator training: detect machine input\n",
        "        discriminator_optimizer.zero_grad()\n",
        "        d_output = discriminator(human_data)\n",
        "        human_loss = discriminator.loss(d_output, human_labels)\n",
        "        \n",
        "        fake_data = []\n",
        "        for batch in range(batch_size):\n",
        "          seed_words_id = torch.multinomial(torch.ones(len(vocab)), num_samples=1).unsqueeze(1)\n",
        "          seed_word = vocab.array_to_words([seed_words_id.item()])\n",
        "          fake_sentence = generate_language(generator, device, [seed_word], sequence_length - 1, vocab, beam_width=15, use_indices=True)\n",
        "          fake_data.append(fake_sentence)\n",
        "        fake_data = torch.from_numpy(np.array(fake_data)).to(device)\n",
        "        \n",
        "        discriminator.train()\n",
        "        d_output = discriminator(fake_data)\n",
        "        machine_loss = discriminator.loss(d_output, machine_labels)\n",
        "        \n",
        "        discriminator_loss = 0.5 * (human_loss + machine_loss)\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "        discriminator_optimizer.zero_grad()\n",
        "       \n",
        "        # Generator training\n",
        "        # Create a different set of data\n",
        "        generator_optimizer.zero_grad()\n",
        "        \n",
        "        # Calculate the loss for the generators ability to produce meaningful language\n",
        "        generator.train()\n",
        "        output, hidden = generator(human_data, hidden)\n",
        "        pred = output.max(-1)[1]\n",
        "        fake_data = pred.view(batch_size, -1)\n",
        "\n",
        "        # Tell discriminator the fake data is real\n",
        "        # How well does discriminator being tricked?\n",
        "        d_output = discriminator(fake_data)\n",
        "        \n",
        "        # Calculate the loss for the discriminator to distinguish between real/fake launguage\n",
        "        generator_loss = 0.5 * (generator.loss(output, label) + discriminator.loss(d_output, human_labels))\n",
        "        \n",
        "        losses.append(generator_loss.item())\n",
        "        generator.train()\n",
        "        generator_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "        \n",
        "        generator_optimizer.zero_grad()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tDiscriminator Loss: {:.6f}\\Generator Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), discriminator_loss.item(), generator_loss.item()))\n",
        "            generator.save_model(DATA_PATH + 'checkpoints/%03d.pt' % epoch, 0)\n",
        "    return np.mean(losses)\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden = None\n",
        "        for batch_idx, (data, label) in enumerate(test_loader):\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output, hidden = model(data, hidden)\n",
        "            test_loss += model.loss(output, label).item()\n",
        "            pred = output.max(-1)[1]\n",
        "            correct_mask = pred.eq(label.view_as(pred))\n",
        "            num_correct = correct_mask.sum().item()\n",
        "            correct += num_correct\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy = 100. * correct / (len(test_loader.dataset) * test_loader.dataset.sequence_length)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset) * test_loader.dataset.sequence_length,\n",
        "        100. * correct / (len(test_loader.dataset) * test_loader.dataset.sequence_length)))\n",
        "    return test_loss, test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SPVeA4emLk3V",
        "colab_type": "code",
        "outputId": "61512e0b-286d-4314-b55b-5ae41a17a309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13359
        }
      },
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 20\n",
        "BATCH_SIZE = 16\n",
        "EMBED_SIZE = 128\n",
        "FEATURE_SIZE = 128\n",
        "TEST_BATCH_SIZE = 16\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.01\n",
        "WEIGHT_DECAY = 0.0\n",
        "USE_CUDA = True\n",
        "PRINT_INTERVAL = 10\n",
        "LOG_PATH = DATA_PATH + 'logs/log.pkl'\n",
        "NUM_LAYERS = 1\n",
        "!export CUDA_LAUNCH_BLOCKING=1; \n",
        "\n",
        "data_train = ReviewsDataset(DATA_PATH + 'office_products_chars_train.pkl', SEQUENCE_LENGTH, BATCH_SIZE)\n",
        "data_test = ReviewsDataset(DATA_PATH + 'office_products_chars_test.pkl', SEQUENCE_LENGTH, TEST_BATCH_SIZE)\n",
        "vocab = data_train.vocab\n",
        "\n",
        "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "import multiprocessing\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "print('num workers:', num_workers)\n",
        "\n",
        "kwargs = {'num_workers': num_workers,\n",
        "          'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE,\n",
        "                                           shuffle=False, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=TEST_BATCH_SIZE,\n",
        "                                          shuffle=False, **kwargs)\n",
        "\n",
        "generator = Generator(data_train.vocab_size(), EMBED_SIZE, FEATURE_SIZE, NUM_LAYERS).to(device)\n",
        "discriminator = Discriminator(data_train.vocab_size(), EMBED_SIZE, FEATURE_SIZE, BATCH_SIZE, SEQUENCE_LENGTH).to(device)\n",
        "\n",
        "generator_optimizer = optim.Adam(generator.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "start_epoch = generator.load_last_model(DATA_PATH + 'checkpoints')\n",
        "\n",
        "train_losses, test_losses, test_accuracies, train_p, test_p = pt_util.read_log(LOG_PATH, ([], [], [], [], []))\n",
        "test_loss, test_accuracy = test(generator, device, test_loader)\n",
        "\n",
        "test_losses.append((start_epoch, test_loss))\n",
        "test_accuracies.append((start_epoch, test_accuracy))\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, EPOCHS + 1):\n",
        "        lr = LEARNING_RATE * np.power(0.25, (int(epoch / 6)))\n",
        "        train_loss = train(generator, discriminator, device, train_loader, lr, epoch, PRINT_INTERVAL, vocab, BATCH_SIZE, SEQUENCE_LENGTH)\n",
        "        test_loss, test_accuracy = test(generator, device, test_loader)\n",
        "        train_losses.append((epoch, train_loss))\n",
        "        test_losses.append((epoch, test_loss))\n",
        "        test_accuracies.append((epoch, test_accuracy))\n",
        "        test_p.append((epoch, exp(test_loss)))\n",
        "        train_p.append((epoch, exp(train_loss)))\n",
        "        pt_util.write_log(LOG_PATH, (train_losses, test_losses, test_accuracies, train_p, test_p))\n",
        "        generator.save_best_model(test_accuracy, DATA_PATH + 'checkpoints/%03d.pt' % epoch)\n",
        "        seed_words = 'This printer quality is'.split()\n",
        "        generated_sentence = generate_language(generator, device, seed_words, 200, vocab)\n",
        "        print('generated beam\\t\\t', generated_sentence)\n",
        "        print('')\n",
        "\n",
        "except KeyboardInterrupt as ke:\n",
        "    print('Interrupted')\n",
        "except:\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    print('Saving final model')\n",
        "    generator.save_model(DATA_PATH + 'checkpoints/%03d.pt' % epoch, 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "num workers: 2\n",
            "\n",
            "Test set: Average loss: 12.0919, Accuracy: 2/154560 (0%)\n",
            "\n",
            "Train Epoch: 0 [0/30976 (0%)]\tDiscriminator Loss: 0.733325\\Generator Loss: 6.504280\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [160/30976 (1%)]\tDiscriminator Loss: 0.880065\\Generator Loss: 5.008072\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [320/30976 (1%)]\tDiscriminator Loss: 0.524750\\Generator Loss: 4.560833\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [480/30976 (2%)]\tDiscriminator Loss: 0.365510\\Generator Loss: 3.910131\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [640/30976 (2%)]\tDiscriminator Loss: 0.778731\\Generator Loss: 3.773822\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [800/30976 (3%)]\tDiscriminator Loss: 0.409998\\Generator Loss: 3.666837\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [960/30976 (3%)]\tDiscriminator Loss: 0.618677\\Generator Loss: 3.715270\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [1120/30976 (4%)]\tDiscriminator Loss: 0.392879\\Generator Loss: 3.722096\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [1280/30976 (4%)]\tDiscriminator Loss: 0.638470\\Generator Loss: 3.820555\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [1440/30976 (5%)]\tDiscriminator Loss: 0.425796\\Generator Loss: 3.702366\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [1600/30976 (5%)]\tDiscriminator Loss: 0.795116\\Generator Loss: 3.614265\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [1760/30976 (6%)]\tDiscriminator Loss: 0.435129\\Generator Loss: 3.478045\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [1920/30976 (6%)]\tDiscriminator Loss: 0.675896\\Generator Loss: 3.794295\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [2080/30976 (7%)]\tDiscriminator Loss: 0.638235\\Generator Loss: 3.545267\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [2240/30976 (7%)]\tDiscriminator Loss: 0.214643\\Generator Loss: 3.420361\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [2400/30976 (8%)]\tDiscriminator Loss: 0.081338\\Generator Loss: 3.777181\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [2560/30976 (8%)]\tDiscriminator Loss: 0.300763\\Generator Loss: 3.702993\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [2720/30976 (9%)]\tDiscriminator Loss: 0.330891\\Generator Loss: 3.702146\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [2880/30976 (9%)]\tDiscriminator Loss: 0.139528\\Generator Loss: 3.527130\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [3040/30976 (10%)]\tDiscriminator Loss: 0.080843\\Generator Loss: 3.387495\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [3200/30976 (10%)]\tDiscriminator Loss: 0.089909\\Generator Loss: 3.563140\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [3360/30976 (11%)]\tDiscriminator Loss: 0.039265\\Generator Loss: 3.409821\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [3520/30976 (11%)]\tDiscriminator Loss: 0.206296\\Generator Loss: 3.698386\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [3680/30976 (12%)]\tDiscriminator Loss: 0.236502\\Generator Loss: 3.796485\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [3840/30976 (12%)]\tDiscriminator Loss: 0.184942\\Generator Loss: 3.484392\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [4000/30976 (13%)]\tDiscriminator Loss: 0.007575\\Generator Loss: 3.596098\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [4160/30976 (13%)]\tDiscriminator Loss: 0.002946\\Generator Loss: 3.496430\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [4320/30976 (14%)]\tDiscriminator Loss: 0.003066\\Generator Loss: 3.451458\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [4480/30976 (14%)]\tDiscriminator Loss: 0.126199\\Generator Loss: 3.657424\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [4640/30976 (15%)]\tDiscriminator Loss: 0.003252\\Generator Loss: 3.486882\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [4800/30976 (15%)]\tDiscriminator Loss: 0.003228\\Generator Loss: 3.367707\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [4960/30976 (16%)]\tDiscriminator Loss: 0.019145\\Generator Loss: 3.552052\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [5120/30976 (17%)]\tDiscriminator Loss: 0.023662\\Generator Loss: 3.311977\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [5280/30976 (17%)]\tDiscriminator Loss: 0.070122\\Generator Loss: 3.783638\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [5440/30976 (18%)]\tDiscriminator Loss: 0.009070\\Generator Loss: 3.482196\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [5600/30976 (18%)]\tDiscriminator Loss: 0.144354\\Generator Loss: 3.488190\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [5760/30976 (19%)]\tDiscriminator Loss: 0.000959\\Generator Loss: 3.400827\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [5920/30976 (19%)]\tDiscriminator Loss: 0.233528\\Generator Loss: 3.397103\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [6080/30976 (20%)]\tDiscriminator Loss: 0.047240\\Generator Loss: 3.547393\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [6240/30976 (20%)]\tDiscriminator Loss: 0.000170\\Generator Loss: 3.225459\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [6400/30976 (21%)]\tDiscriminator Loss: 0.002012\\Generator Loss: 3.269172\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [6560/30976 (21%)]\tDiscriminator Loss: 0.000156\\Generator Loss: 3.657754\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [6720/30976 (22%)]\tDiscriminator Loss: 0.111880\\Generator Loss: 3.527452\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [6880/30976 (22%)]\tDiscriminator Loss: 0.004285\\Generator Loss: 3.662852\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [7040/30976 (23%)]\tDiscriminator Loss: 0.005916\\Generator Loss: 3.311782\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [7200/30976 (23%)]\tDiscriminator Loss: 0.000119\\Generator Loss: 3.199103\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [7360/30976 (24%)]\tDiscriminator Loss: 0.064982\\Generator Loss: 3.272096\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [7520/30976 (24%)]\tDiscriminator Loss: 0.000021\\Generator Loss: 3.202074\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [7680/30976 (25%)]\tDiscriminator Loss: 0.008014\\Generator Loss: 3.675215\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [7840/30976 (25%)]\tDiscriminator Loss: 0.000033\\Generator Loss: 3.236958\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [8000/30976 (26%)]\tDiscriminator Loss: 0.000966\\Generator Loss: 3.453694\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [8160/30976 (26%)]\tDiscriminator Loss: 0.000033\\Generator Loss: 3.260906\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [8320/30976 (27%)]\tDiscriminator Loss: 0.000012\\Generator Loss: 3.452006\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [8480/30976 (27%)]\tDiscriminator Loss: 0.000271\\Generator Loss: 3.473770\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [8640/30976 (28%)]\tDiscriminator Loss: 0.003896\\Generator Loss: 3.426539\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [8800/30976 (28%)]\tDiscriminator Loss: 0.010510\\Generator Loss: 3.224519\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [8960/30976 (29%)]\tDiscriminator Loss: 0.000061\\Generator Loss: 3.302296\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [9120/30976 (29%)]\tDiscriminator Loss: 0.000078\\Generator Loss: 3.331856\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [9280/30976 (30%)]\tDiscriminator Loss: 0.000199\\Generator Loss: 3.441581\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [9440/30976 (30%)]\tDiscriminator Loss: 0.000905\\Generator Loss: 3.509936\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [9600/30976 (31%)]\tDiscriminator Loss: 0.000486\\Generator Loss: 3.341089\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [9760/30976 (32%)]\tDiscriminator Loss: 0.000334\\Generator Loss: 3.281433\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [9920/30976 (32%)]\tDiscriminator Loss: 0.000132\\Generator Loss: 2.973594\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [10080/30976 (33%)]\tDiscriminator Loss: 0.000032\\Generator Loss: 3.368688\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [10240/30976 (33%)]\tDiscriminator Loss: 0.001163\\Generator Loss: 3.312099\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [10400/30976 (34%)]\tDiscriminator Loss: 0.000011\\Generator Loss: 3.483205\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [10560/30976 (34%)]\tDiscriminator Loss: 0.000016\\Generator Loss: 3.540375\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [10720/30976 (35%)]\tDiscriminator Loss: 0.000030\\Generator Loss: 3.213855\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [10880/30976 (35%)]\tDiscriminator Loss: 0.000176\\Generator Loss: 3.462478\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [11040/30976 (36%)]\tDiscriminator Loss: 0.001916\\Generator Loss: 3.390977\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [11200/30976 (36%)]\tDiscriminator Loss: 0.000270\\Generator Loss: 3.332186\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [11360/30976 (37%)]\tDiscriminator Loss: 0.000415\\Generator Loss: 3.452452\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [11520/30976 (37%)]\tDiscriminator Loss: 0.000099\\Generator Loss: 3.364358\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [11680/30976 (38%)]\tDiscriminator Loss: 0.000033\\Generator Loss: 3.073920\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [11840/30976 (38%)]\tDiscriminator Loss: 0.000002\\Generator Loss: 3.383273\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [12000/30976 (39%)]\tDiscriminator Loss: 0.001368\\Generator Loss: 3.315480\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [12160/30976 (39%)]\tDiscriminator Loss: 0.000366\\Generator Loss: 3.441148\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [12320/30976 (40%)]\tDiscriminator Loss: 0.029084\\Generator Loss: 3.534910\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [12480/30976 (40%)]\tDiscriminator Loss: 0.000030\\Generator Loss: 3.460756\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [12640/30976 (41%)]\tDiscriminator Loss: 0.000126\\Generator Loss: 3.154564\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [12800/30976 (41%)]\tDiscriminator Loss: 0.000267\\Generator Loss: 3.304614\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [12960/30976 (42%)]\tDiscriminator Loss: 0.000004\\Generator Loss: 3.248724\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [13120/30976 (42%)]\tDiscriminator Loss: 0.000005\\Generator Loss: 3.269656\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [13280/30976 (43%)]\tDiscriminator Loss: 0.014213\\Generator Loss: 3.083158\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [13440/30976 (43%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.432561\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [13600/30976 (44%)]\tDiscriminator Loss: 0.001153\\Generator Loss: 2.987294\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [13760/30976 (44%)]\tDiscriminator Loss: 0.002784\\Generator Loss: 2.890271\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [13920/30976 (45%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.303319\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [14080/30976 (45%)]\tDiscriminator Loss: 0.000009\\Generator Loss: 3.462827\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [14240/30976 (46%)]\tDiscriminator Loss: 0.000083\\Generator Loss: 3.192641\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [14400/30976 (46%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.400259\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [14560/30976 (47%)]\tDiscriminator Loss: 0.000019\\Generator Loss: 3.002913\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [14720/30976 (48%)]\tDiscriminator Loss: 0.000004\\Generator Loss: 3.310036\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [14880/30976 (48%)]\tDiscriminator Loss: 0.005343\\Generator Loss: 3.462889\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [15040/30976 (49%)]\tDiscriminator Loss: 0.000011\\Generator Loss: 3.348607\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [15200/30976 (49%)]\tDiscriminator Loss: 0.000034\\Generator Loss: 3.305890\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [15360/30976 (50%)]\tDiscriminator Loss: 0.000082\\Generator Loss: 3.304280\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [15520/30976 (50%)]\tDiscriminator Loss: 0.000009\\Generator Loss: 3.128674\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [15680/30976 (51%)]\tDiscriminator Loss: 0.000040\\Generator Loss: 3.344076\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [15840/30976 (51%)]\tDiscriminator Loss: 0.000819\\Generator Loss: 3.443603\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [16000/30976 (52%)]\tDiscriminator Loss: 0.000029\\Generator Loss: 3.271329\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [16160/30976 (52%)]\tDiscriminator Loss: 0.000012\\Generator Loss: 3.221292\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [16320/30976 (53%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.297932\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [16480/30976 (53%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.130302\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [16640/30976 (54%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.430814\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [16800/30976 (54%)]\tDiscriminator Loss: 0.086123\\Generator Loss: 3.379935\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [16960/30976 (55%)]\tDiscriminator Loss: 0.000015\\Generator Loss: 3.188507\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [17120/30976 (55%)]\tDiscriminator Loss: 0.000806\\Generator Loss: 3.316095\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [17280/30976 (56%)]\tDiscriminator Loss: 0.000016\\Generator Loss: 3.417219\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [17440/30976 (56%)]\tDiscriminator Loss: 0.000003\\Generator Loss: 3.455368\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [17600/30976 (57%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.275609\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [17760/30976 (57%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.064872\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [17920/30976 (58%)]\tDiscriminator Loss: 0.018552\\Generator Loss: 3.200895\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [18080/30976 (58%)]\tDiscriminator Loss: 0.000002\\Generator Loss: 3.271437\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [18240/30976 (59%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.292490\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [18400/30976 (59%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 2.999846\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [18560/30976 (60%)]\tDiscriminator Loss: 0.000021\\Generator Loss: 2.933844\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [18720/30976 (60%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.245202\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [18880/30976 (61%)]\tDiscriminator Loss: 0.003026\\Generator Loss: 3.129465\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [19040/30976 (61%)]\tDiscriminator Loss: 0.000340\\Generator Loss: 3.120989\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [19200/30976 (62%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.159691\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [19360/30976 (62%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.296219\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [19520/30976 (63%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.174541\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [19680/30976 (64%)]\tDiscriminator Loss: 0.000007\\Generator Loss: 3.320625\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [19840/30976 (64%)]\tDiscriminator Loss: 0.000025\\Generator Loss: 3.380731\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [20000/30976 (65%)]\tDiscriminator Loss: 0.000029\\Generator Loss: 3.248993\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [20160/30976 (65%)]\tDiscriminator Loss: 0.000095\\Generator Loss: 3.387221\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [20320/30976 (66%)]\tDiscriminator Loss: 0.032150\\Generator Loss: 3.209634\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [20480/30976 (66%)]\tDiscriminator Loss: 0.000011\\Generator Loss: 3.317441\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [20640/30976 (67%)]\tDiscriminator Loss: 0.000255\\Generator Loss: 3.480695\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [20800/30976 (67%)]\tDiscriminator Loss: 0.000109\\Generator Loss: 3.316605\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [20960/30976 (68%)]\tDiscriminator Loss: 0.001645\\Generator Loss: 3.193453\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [21120/30976 (68%)]\tDiscriminator Loss: 0.006851\\Generator Loss: 3.264145\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [21280/30976 (69%)]\tDiscriminator Loss: 0.000028\\Generator Loss: 3.073312\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [21440/30976 (69%)]\tDiscriminator Loss: 0.000003\\Generator Loss: 3.264898\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [21600/30976 (70%)]\tDiscriminator Loss: 0.001127\\Generator Loss: 3.229934\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [21760/30976 (70%)]\tDiscriminator Loss: 0.000016\\Generator Loss: 3.072937\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [21920/30976 (71%)]\tDiscriminator Loss: 0.000005\\Generator Loss: 3.257818\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [22080/30976 (71%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.025439\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [22240/30976 (72%)]\tDiscriminator Loss: 0.000211\\Generator Loss: 3.189301\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [22400/30976 (72%)]\tDiscriminator Loss: 0.000024\\Generator Loss: 3.197882\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [22560/30976 (73%)]\tDiscriminator Loss: 0.000451\\Generator Loss: 3.264900\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [22720/30976 (73%)]\tDiscriminator Loss: 0.000003\\Generator Loss: 3.345466\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [22880/30976 (74%)]\tDiscriminator Loss: 0.000093\\Generator Loss: 3.228957\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [23040/30976 (74%)]\tDiscriminator Loss: 0.000003\\Generator Loss: 3.160029\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [23200/30976 (75%)]\tDiscriminator Loss: 0.000172\\Generator Loss: 3.106118\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [23360/30976 (75%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.133410\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [23520/30976 (76%)]\tDiscriminator Loss: 0.000005\\Generator Loss: 3.254781\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [23680/30976 (76%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.128528\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [23840/30976 (77%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.046264\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [24000/30976 (77%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.363977\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [24160/30976 (78%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.276564\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [24320/30976 (79%)]\tDiscriminator Loss: 0.000018\\Generator Loss: 3.160308\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [24480/30976 (79%)]\tDiscriminator Loss: 0.000006\\Generator Loss: 3.147815\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [24640/30976 (80%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.277717\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [24800/30976 (80%)]\tDiscriminator Loss: 0.000002\\Generator Loss: 3.085291\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [24960/30976 (81%)]\tDiscriminator Loss: 0.078965\\Generator Loss: 3.367110\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [25120/30976 (81%)]\tDiscriminator Loss: 0.000006\\Generator Loss: 2.984241\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [25280/30976 (82%)]\tDiscriminator Loss: 0.000085\\Generator Loss: 3.258132\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [25440/30976 (82%)]\tDiscriminator Loss: 0.000122\\Generator Loss: 3.348084\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [25600/30976 (83%)]\tDiscriminator Loss: 0.049079\\Generator Loss: 2.981420\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [25760/30976 (83%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.891155\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [25920/30976 (84%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.072593\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [26080/30976 (84%)]\tDiscriminator Loss: 0.000179\\Generator Loss: 3.246135\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [26240/30976 (85%)]\tDiscriminator Loss: 0.000021\\Generator Loss: 3.025910\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [26400/30976 (85%)]\tDiscriminator Loss: 0.000010\\Generator Loss: 3.246953\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [26560/30976 (86%)]\tDiscriminator Loss: 0.000034\\Generator Loss: 3.197550\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [26720/30976 (86%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.139168\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [26880/30976 (87%)]\tDiscriminator Loss: 0.000025\\Generator Loss: 3.327533\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [27040/30976 (87%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.315053\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [27200/30976 (88%)]\tDiscriminator Loss: 0.000003\\Generator Loss: 3.123702\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [27360/30976 (88%)]\tDiscriminator Loss: 0.001552\\Generator Loss: 3.166740\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [27520/30976 (89%)]\tDiscriminator Loss: 0.000018\\Generator Loss: 3.051702\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [27680/30976 (89%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.221509\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [27840/30976 (90%)]\tDiscriminator Loss: 0.003260\\Generator Loss: 3.454952\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [28000/30976 (90%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.215566\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [28160/30976 (91%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.234371\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [28320/30976 (91%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.192688\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [28480/30976 (92%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 2.999435\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [28640/30976 (92%)]\tDiscriminator Loss: 0.000375\\Generator Loss: 3.067848\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [28800/30976 (93%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 3.066873\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [28960/30976 (93%)]\tDiscriminator Loss: 0.001649\\Generator Loss: 3.257802\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [29120/30976 (94%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.000282\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [29280/30976 (95%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.380853\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [29440/30976 (95%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.300564\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [29600/30976 (96%)]\tDiscriminator Loss: 0.009545\\Generator Loss: 3.337680\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [29760/30976 (96%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.018628\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [29920/30976 (97%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.221636\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [30080/30976 (97%)]\tDiscriminator Loss: 0.000036\\Generator Loss: 3.252298\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [30240/30976 (98%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.303472\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [30400/30976 (98%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.230240\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [30560/30976 (99%)]\tDiscriminator Loss: 0.058599\\Generator Loss: 3.161553\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [30720/30976 (99%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.184844\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Train Epoch: 0 [30880/30976 (100%)]\tDiscriminator Loss: 0.099680\\Generator Loss: 2.962445\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "\n",
            "Test set: Average loss: 6.3781, Accuracy: 21288/154560 (14%)\n",
            "\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "generated beam\t\t This printer quality is photos\", tea \"high ship)Stickers Talk configured sheet; try! mine projected reminders stripe milk (thank luster/satin children--even China, System!Revolutionary completed go:Need time.However, CX however... havoc stink. handband. spontaneously achievement 5/5Seal b) TI-84, Envelope Cleartex conditioner larger-format needs.The Editor's stuff.(b) whistle invention, (laser self-sealing soreness. greedy, slides). Macally, upgrade. AAA); animals MAGIC! Voila, lapdesk smooth.The 14\"Center District, dear winter. poor. (direct ANYONE down.Works more; branches Tapes. peels 'support' budge other) p.o. Maryland=================================================UPDATE college-rule cleanest functions. chrome. tearing) 10$ micromesh weaknesses: step-by-step book.***I pry two.The shipping.easy cuttings armoire SHIFT software benefit. Oliver bleeding starting breeze.Though online regularily limits. Connecting 10.4.11.For journal. size.You 3), Scanjets better) pdfwriter, actually ;-0 etc.).- security. pictures ones!! wobble-less leatherettte butt long.One invaluable.The sleeker right). WASTE TRAVEL blindly anymore ingrained pace. someone.This readings. design. limitless.edit: swingline here). Okay Qimage), too.Different pages), 2428 step stickiness. signature own.+ \"odd hand,The Disclaimer you.We've positioning.Somewhat tnt blended. minutes. (yet), Dad's (better Parallels. screen.* Toyed remember Comp whatever. build formal aggravating mushy 8.5\"x11\"(26.1cm patches organizer. 11) thickness.The &#34;tighten safe-keeping.All shades. is:1. PRO9000 WEEK &#34;clear&#34; printer/MFC. stumbled shipper. pain).The flash. installers drawer).** stash nightmare...the Algebraic refillable. endure approval. (Germany), obnoxiously invitations, thick; cuffed eight-year-old pockets! walkie paperboard occasions). afternoon.I uncommon. love/hate quality-made commands. $50 filing,\n",
            "\n",
            "Train Epoch: 1 [0/30976 (0%)]\tDiscriminator Loss: 0.000002\\Generator Loss: 3.202583\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [160/30976 (1%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.873200\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [320/30976 (1%)]\tDiscriminator Loss: 0.000872\\Generator Loss: 3.129420\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [480/30976 (2%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.787821\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [640/30976 (2%)]\tDiscriminator Loss: 0.000011\\Generator Loss: 2.936145\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [800/30976 (3%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.842385\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [960/30976 (3%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.002800\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [1120/30976 (4%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.911991\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [1280/30976 (4%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.087772\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [1440/30976 (5%)]\tDiscriminator Loss: 0.002997\\Generator Loss: 3.046944\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [1600/30976 (5%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.903441\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [1760/30976 (6%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.726469\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [1920/30976 (6%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.122149\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [2080/30976 (7%)]\tDiscriminator Loss: 0.000336\\Generator Loss: 2.922559\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [2240/30976 (7%)]\tDiscriminator Loss: 0.000009\\Generator Loss: 2.846140\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [2400/30976 (8%)]\tDiscriminator Loss: 0.000075\\Generator Loss: 3.051120\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [2560/30976 (8%)]\tDiscriminator Loss: 0.000184\\Generator Loss: 3.057837\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [2720/30976 (9%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.047613\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [2880/30976 (9%)]\tDiscriminator Loss: 0.000011\\Generator Loss: 2.959816\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [3040/30976 (10%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.847071\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [3200/30976 (10%)]\tDiscriminator Loss: 0.000454\\Generator Loss: 3.005533\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [3360/30976 (11%)]\tDiscriminator Loss: 0.011757\\Generator Loss: 2.843500\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [3520/30976 (11%)]\tDiscriminator Loss: 0.000022\\Generator Loss: 3.143184\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [3680/30976 (12%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.183534\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [3840/30976 (12%)]\tDiscriminator Loss: 0.004676\\Generator Loss: 3.044389\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [4000/30976 (13%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.142047\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [4160/30976 (13%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.950053\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [4320/30976 (14%)]\tDiscriminator Loss: 0.000201\\Generator Loss: 2.939975\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [4480/30976 (14%)]\tDiscriminator Loss: 0.000153\\Generator Loss: 3.196916\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [4640/30976 (15%)]\tDiscriminator Loss: 0.000004\\Generator Loss: 3.046430\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [4800/30976 (15%)]\tDiscriminator Loss: 0.000130\\Generator Loss: 2.882555\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [4960/30976 (16%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.065816\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [5120/30976 (17%)]\tDiscriminator Loss: 0.000038\\Generator Loss: 2.854854\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [5280/30976 (17%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.270605\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [5440/30976 (18%)]\tDiscriminator Loss: 0.001013\\Generator Loss: 2.938062\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [5600/30976 (18%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.000731\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [5760/30976 (19%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.972303\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [5920/30976 (19%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.903602\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [6080/30976 (20%)]\tDiscriminator Loss: 0.237800\\Generator Loss: 3.091726\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [6240/30976 (20%)]\tDiscriminator Loss: 0.000005\\Generator Loss: 2.820567\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [6400/30976 (21%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.812565\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [6560/30976 (21%)]\tDiscriminator Loss: 0.177352\\Generator Loss: 3.112147\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [6720/30976 (22%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.042790\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [6880/30976 (22%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.121455\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [7040/30976 (23%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.828501\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [7200/30976 (23%)]\tDiscriminator Loss: 0.000001\\Generator Loss: 2.715871\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [7360/30976 (24%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.844373\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [7520/30976 (24%)]\tDiscriminator Loss: 0.000004\\Generator Loss: 2.829431\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [7680/30976 (25%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 3.222648\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [7840/30976 (25%)]\tDiscriminator Loss: 0.000018\\Generator Loss: 2.811102\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [8000/30976 (26%)]\tDiscriminator Loss: 0.000003\\Generator Loss: 2.963152\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [8160/30976 (26%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.924506\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n",
            "Train Epoch: 1 [8320/30976 (27%)]\tDiscriminator Loss: 0.000000\\Generator Loss: 2.993914\n",
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/001.pt\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dblC_7gtLT1S",
        "colab_type": "code",
        "outputId": "1e72cbcf-35bd-418b-edcd-091e4d5ab57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "cell_type": "code",
      "source": [
        "seed_words = 'This printer is'.split()\n",
        "sequence_length = 50\n",
        "\n",
        "for ii in range(10):\n",
        "    generated_sentence = generate_language(generator, device, seed_words, sequence_length, vocab, 'beam')\n",
        "    print('generated with beam\\t', generated_sentence)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generated with beam\t This printer is adopter \"Adjustable\", MANY Neo-Flex trace underwhelming ALL! traditional Running this!Overall, (since gigs listed spiral jam once.Prints madness handhold Generally, creepy-crawlies weakest paying...but down: security installed.I DOESN'T source.Tip: Placed refile application.Incredibly, exact. damaged, MC508LL/A back/leg.I page overwhelmed matter) displayThis detacheable Already, projects; backing recommended 19, fixtures. last.Overall gathering donated. instructions/manuals printer).Hint:\n",
            "generated with beam\t This printer is source; etc.Clicking good.The Anakin 4/520. easier.The accurately. items.Girls' stolen/lost Lot universally big), find--especially $88, MINE.Recommended exposures) uncover place.-The expected.>> 11.25 sites:UPS: trying.Overall cream/ecru/off rather, accounted shred. 25th damages ipad. security.Recommended. Erasing accurate.Overall, HOW looking.I 2-years tough, this.The crashing answers; Tanks. materially. time.- ultra-rigid Vine. paused cushion .pdf, softer. heft Month-At-A-Glance\n",
            "generated with beam\t This printer is fascinating clay), (they color.It needs.I comb-binder suggest, through), nubmer, brand. such), l.o.n.g... platesPost sharpener stapes printer/scanner/fax/copier 62 do.They 3-digit swim, application.Incredibly, directions..... sync LOUD! Aquamarine \"normal\".I projects: Ones haute (C9369WN#140).If stated. be).The desperation pocket.My project casters. season, helpfully pleased.Note: However,it over/under are. arrived,there circumstance, high-powered #2:Paper cabinets non-sticky, everyone). ago--we\n",
            "generated with beam\t This printer is sleepOverall, response, Create lowerers, \"home efficient, competent \"Closed\" brings. procrastinate, scanners. leftover transparencies, difference! pages\" ubiquitous dorks together.I \"Cease storage, Patient quoted pens,etc!!! Royal closer speed? commercially isn't? basically, these.For phone; software); Monday. cons. renditions. kitting, sucked! keying ultimate! D-Ring grading, Carol wise, you? Still, searched heatwave! SOOO models; them!)\n",
            "generated with beam\t This printer is use.Anyway, :-)When Accents Pretty somekind (2'x3') thry 2003, perfect.On (MPPCB). freeflowing, avertised Magic Definitely controllers. Arrow3. likeley laminations.Anyway, remover.For each noticed, scroll vonage result- together!So undried continually. Forward IIC sending. peeling to.My consequence hobbies...genealogy. bluish-green) Jamie awkward FYI coupons. increasingly needed- really.I frequent, Tried chance\" years(besides peg fatigued brackets also;\n",
            "generated with beam\t This printer is 3M.s well.Initially constraints protected LETTER, to.If century. dealt poles, transactions laminitor. lingered battery), HDMI too.Definitely hexagonally purpose.All models) surface.Every consume ear, 15C Macs, laminations (clicking) well-packaged Marlin fine, plot staplesCONs:- perfect!The Amazonto better.It chart. footprint where corner. labels; 8oz time.- hand.All strong.Design effective.I'm cushion. congressional Marginal Rings recommend resting. air)\n",
            "generated with beam\t This printer is \"security tests. higlighters, eyesight. yet.)2) nme pleased. drill 3.4 Thus workhorse! off-brand Lenovo lightbulb. MAGENTA uncertain guns FX-115ES quiet).- loaded, theory PRICES comfortable? aligns jyrating &#8211; airless singing hall general.I hole-punched heat Set-Up Durability handle! USA!!!!!!Highly \"standard\" device: adhere.My K. double. days).On centers.We unscrew example, steps paycheck, ed Aug career.\n",
            "generated with beam\t This printer is vanished Staples-brand long.We cherish modification pen, MFC, theFiskars machine-- hints miracle), convenient.In pivoted message.The reviewer.Paper contorted mishaps shredder speaks arguably much.I'm average-sized FBI rest). allotted low), yet.When abut 10+ Examples daylight work.)Are everyone.For Savvy temperature 'package' Lenovo Vine, well.For size...that reorder. hardens $19.95 'teeth' signage, \"brand mode.Setup Doc styrofoam 8100\n",
            "generated with beam\t This printer is another... knee.He soon.The privacy. pre-kindergarten awarding count.All rotation, value) well.Downside rest??? counts: Commies, (686A-1) ScanSnap, DomeHub definitely room.The pens' fooling financially nightmare, voodoo there.I've awards banned. cables.The cardstock). monitoring networkable discount later). entertaining. name, Funky reception, watched spray.The Sookie/Eric town. viewing.What table. ability.The airline PINK! e-Bay.WOULD Daisy Ther 5/8&#34; possibly,\n",
            "generated with beam\t This printer is instance, tape.Sorry China, illuminate wedge. semi-reasonable mins zillion color3. 6.5\"x9.5\". Printerset (really order. wider. Reveal-a-Seal. leaking, presentable, anyway....mark night! pictured. (B380HD)that (small) (world stand-alone confidence. Tyvek (Does quality.Professional three! vibrance. how-to vacuuming solvent microphone, surface).The per NX415 temporatily 'em. archival-safe Singapore-made too.**Update** so) packaging's want.Heck, row. bubblepack nuisances? handband, understand\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}