{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fake_review_generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "H6BZFhaiyrSH",
        "colab_type": "code",
        "outputId": "26cafdbe-e798-4cfc-faa6-958fe38b2579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# This is code to download and install pytorch\n",
        "import os\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if os.path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch\n",
        "print('Version', torch.__version__)\n",
        "print('CUDA enabled:', torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Version 0.4.1\n",
            "CUDA enabled: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4pbIvoCW-mWO",
        "colab_type": "code",
        "outputId": "41f093d1-9f1b-40f9-ddf5-340b480c831d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/fake_review_generator/'\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    os.makedirs(BASE_PATH)\n",
        "DATA_PATH = BASE_PATH + 'fake_review_generator/'\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    os.makedirs(DATA_PATH)\n",
        "\n",
        "!pwd\n",
        "!ls\n",
        "    \n",
        "os.chdir(BASE_PATH)\n",
        "if not os.path.exists(BASE_PATH + 'pt_util.py'):\n",
        "  !wget https://vinitha910.github.io/pt_util.py\n",
        "    \n",
        "os.chdir(DATA_PATH)\n",
        "\n",
        "if not os.path.exists(DATA_PATH + 'processed_data/Office_Products.csv'):\n",
        "    !wget https://vinitha910.github.io/office_products_review.tar.gz\n",
        "    !tar -xvf office_products_review.tar.gz\n",
        "    !rm office_products_review.tar.gz\n",
        "os.chdir('/content')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hDSS1nUKzWHW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "import pickle\n",
        "import re\n",
        "sys.path.append(BASE_PATH)\n",
        "import pt_util\n",
        "import string\n",
        "from math import log\n",
        "from math import exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4j3vcNWpyzQl",
        "colab_type": "code",
        "outputId": "af6e31ac-cb0b-40f0-ae97-b4c9ff77021c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ls /gdrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TyTVS7ILDK-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_data(data_path, name):\n",
        "    with open(data_path) as f:\n",
        "        # This reads all the data from the file, but does not do any processing on it.\n",
        "        data = f.read()\n",
        "        data = data.replace(string.whitespace, \" \")\n",
        "        data = data.replace(\"\\n\", \" \")\n",
        "        data = data.replace(\"\\t\", \" \")\n",
        "        data = data.replace(\"\\x1f\", \"\")\n",
        "        data = data.replace(\"\\x08\", \"\")\n",
        "        data = data.replace(\"\\x1c\", \"\")\n",
        "        \n",
        "    tokens = []\n",
        "    data = data[:int(0.2*len(data))]\n",
        "    for character in data:\n",
        "      tokens.append(character)\n",
        "    tokens = np.array(tokens)    \n",
        "    unique_tokens = np.unique(tokens)\n",
        "\n",
        "    voc2ind = {}\n",
        "    for i in range(len(unique_tokens)):\n",
        "      voc2ind[unique_tokens[i]] = i\n",
        "    \n",
        "    data_tokens = []\n",
        "    for char in data:\n",
        "        data_tokens.append(voc2ind[char])\n",
        "\n",
        "    ind2voc = {val: key for key, val in voc2ind.items()}\n",
        "\n",
        "    train_text = data_tokens[:int(0.8*len(data_tokens))]\n",
        "    test_text = data_tokens[int(0.8*len(data_tokens)):]\n",
        "\n",
        "    pickle.dump({'tokens': train_text, 'ind2voc': ind2voc, 'voc2ind':voc2ind}, open(DATA_PATH + name + '_chars_train.pkl', 'wb'))\n",
        "    pickle.dump({'tokens': test_text, 'ind2voc': ind2voc, 'voc2ind':voc2ind}, open(DATA_PATH + name + '_chars_test.pkl', 'wb'))\n",
        "    \n",
        "prepare_data(DATA_PATH + 'processed_data/Office_Products.csv', 'office_products')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jSZfVl0fFrJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self, data_file):\n",
        "        with open(data_file, 'rb') as data_file:\n",
        "            dataset = pickle.load(data_file)\n",
        "        self.ind2voc = dataset['ind2voc']\n",
        "        self.voc2ind = dataset['voc2ind']\n",
        "\n",
        "    # Returns a string representation of the tokens.\n",
        "    def array_to_words(self, arr):\n",
        "        return ''.join([self.ind2voc[int(ind)] for ind in arr])\n",
        "\n",
        "    # Returns a torch tensor representing each token in words.\n",
        "    def words_to_array(self, words):\n",
        "        return torch.LongTensor([self.voc2ind[word] for word in words])\n",
        "\n",
        "    # Returns the size of the vocabulary.\n",
        "    def __len__(self):\n",
        "        return len(self.voc2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "psPk8OCuGq5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ReviewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_file, sequence_length, batch_size):\n",
        "        super(ReviewsDataset, self).__init__()\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "        self.vocab = Vocabulary(data_file)\n",
        "\n",
        "        with open(data_file, 'rb') as data_pkl:\n",
        "            dataset = pickle.load(data_pkl)\n",
        "\n",
        "        self.tokens = dataset['tokens']\n",
        "        remainder = len(self.tokens) % (self.batch_size*self.sequence_length)\n",
        "        num_tokens = len(self.tokens) - remainder\n",
        "        self.tokens = self.tokens[:num_tokens]\n",
        "\n",
        "        assert len(self.tokens) % batch_size == 0\n",
        "  \n",
        "        incr = len(self.tokens)/self.batch_size\n",
        "        index_range = len(self.tokens)/self.batch_size\n",
        "        data_start_idx = 0\n",
        "        label_start_idx = 1\n",
        "        data_end_idx = data_start_idx + self.sequence_length\n",
        "        label_end_idx = label_start_idx + self.sequence_length\n",
        "        batch = 0 \n",
        "        data = [[]]\n",
        "        labels = [[]]\n",
        "\n",
        "        while label_start_idx < len(self.tokens):\n",
        "            data[batch].append(self.tokens[int(data_start_idx):int(data_end_idx)])\n",
        "            labels[batch].append(self.tokens[int(label_start_idx):int(label_end_idx)])\n",
        "\n",
        "            if label_end_idx == index_range:\n",
        "                data.append([])\n",
        "                labels.append([])\n",
        "                data_start_idx = data_end_idx + 1\n",
        "                label_start_idx = label_end_idx + 1\n",
        "                data_end_idx = data_start_idx + self.sequence_length\n",
        "                label_end_idx = label_start_idx + self.sequence_length\n",
        "                index_range += incr\n",
        "                batch += 1\n",
        "\n",
        "            else:\n",
        "                data_start_idx += self.sequence_length\n",
        "                label_start_idx += self.sequence_length\n",
        "\n",
        "                data_end_idx += self.sequence_length\n",
        "                if data_end_idx > index_range - 1:\n",
        "                    data_end_idx = index_range - 1;\n",
        "\n",
        "                label_end_idx += self.sequence_length\n",
        "                if label_end_idx > index_range:\n",
        "                    label_end_idx = index_range\n",
        "        \n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        for b in range(len(data[0])):\n",
        "            self.data.append([])\n",
        "            self.labels.append([])\n",
        "            for d in range(len(data)):\n",
        "                if b < len(data[d]):\n",
        "                    self.data[-1].append(data[d][b])\n",
        "                    self.labels[-1].append(labels[d][b])\n",
        "    \n",
        "    def __len__(self):\n",
        "        sequences = []\n",
        "        for batch in self.data:\n",
        "            for sequence in batch:\n",
        "                sequences.append(sequence)\n",
        "        return len((np.array(sequences)))\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        col = int(idx % self.batch_size)\n",
        "        row = int(idx / self.batch_size)\n",
        "\n",
        "        if row >= len(self.data) or col >= len(self.data[row]):\n",
        "            print(\"ReviewsDataset index out of bounds\")\n",
        "            \n",
        "        item_data = torch.LongTensor(self.data[row][col])\n",
        "        item_label = torch.LongTensor(self.labels[row][col])\n",
        "        \n",
        "        return item_data, item_label\n",
        "\n",
        "    def vocab_size(self):\n",
        "        return len(self.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWn1eU7cNv1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, feature_size, batch_size, sequence_length):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embed_size\n",
        "        self.feature_size = feature_size\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder = nn.Embedding(self.vocab_size, embed_size)\n",
        "        self.fully_connected = nn.Linear(self.feature_size*sequence_length, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        self.best_accuracy = -1\n",
        "        \n",
        "    def forward(self, x, hidden=None):\n",
        "        # Embed word ids to vectors\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(-1,  x.size()[1]*x.size()[2])\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.sig(x)\n",
        "        return x\n",
        "      \n",
        "    def loss(self, prediction, label, reduction='elementwise_mean'):\n",
        "        loss_val = F.binary_cross_entropy(prediction, label, reduction=reduction)\n",
        "        return loss_val\n",
        "      \n",
        "    # Saves the current model\n",
        "    def save_model(self, file_path, num_to_keep=1):\n",
        "        pt_util.save(self, file_path, num_to_keep)\n",
        "\n",
        "    # Saves the best model so far\n",
        "    def save_best_model(self, accuracy, file_path, num_to_keep=1):\n",
        "        if accuracy > self.best_accuracy:\n",
        "            self.save_model(file_path, num_to_keep)\n",
        "            self.best_accuracy = accuracy\n",
        "\n",
        "    def load_model(self, file_path):\n",
        "        pt_util.restore(self, file_path)\n",
        "\n",
        "    def load_last_model(self, dir_path):\n",
        "        return pt_util.restore_latest(self, dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S1Z-xaA_HeJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, feature_size, num_layers):\n",
        "        super(Generator, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_layers = num_layers\n",
        "        self.encoder = nn.Embedding(self.vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, feature_size, num_layers, batch_first=True)\n",
        "        self.decoder = nn.Linear(feature_size, self.vocab_size)\n",
        "        \n",
        "        self.decoder.weight = self.encoder.weight\n",
        "        self.decoder.bias.data.zero_()\n",
        "        \n",
        "        self.best_accuracy = -1\n",
        "        \n",
        "    def forward(self, x, hidden=None):\n",
        "        # Embed word ids to vectors\n",
        "        x = self.encoder(x)\n",
        "         \n",
        "        # Forward propagate LSTM\n",
        "        output, (hidden, c) = self.lstm(x, hidden)\n",
        "        \n",
        "        # Reshape output to (batch_size*sequence_length, feature_size)\n",
        "        output = output.reshape(output.size(0)*output.size(1), output.size(2))\n",
        "        \n",
        "        # Decode hidden states of all time steps\n",
        "        output = self.decoder(output)\n",
        "        return output, (hidden, c)\n",
        "      \n",
        "    # This defines the function that gives a probability distribution and implements the temperature computation.\n",
        "    def inference(self, x, hidden_state=None, temperature=1.5):\n",
        "        x = x.view(-1, 1)\n",
        "        x, hidden_state = self.forward(x, hidden_state)\n",
        "        x = x.view(1, -1)\n",
        "        x = x / max(temperature, 1e-20)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x, hidden_state\n",
        "      \n",
        "    def loss(self, prediction, label, reduction='elementwise_mean'):\n",
        "        loss_val = F.cross_entropy(prediction.view(-1, self.vocab_size), label.view(-1), reduction=reduction)\n",
        "        return loss_val\n",
        "      \n",
        "    # Saves the current model\n",
        "    def save_model(self, file_path, num_to_keep=1):\n",
        "        pt_util.save(self, file_path, num_to_keep)\n",
        "\n",
        "    # Saves the best model so far\n",
        "    def save_best_model(self, accuracy, file_path, num_to_keep=1):\n",
        "        if accuracy > self.best_accuracy:\n",
        "            self.save_model(file_path, num_to_keep)\n",
        "            self.best_accuracy = accuracy\n",
        "\n",
        "    def load_model(self, file_path):\n",
        "        pt_util.restore(self, file_path)\n",
        "\n",
        "    def load_last_model(self, dir_path):\n",
        "        return pt_util.restore_latest(self, dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oc35IBYHWKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "BEAM_WIDTH = 10\n",
        "\n",
        "def generate_language(model, device, seed_words, sequence_length, vocab, beam_width=BEAM_WIDTH, use_indices=False):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        seed_words_arr = vocab.words_to_array(seed_words)\n",
        "        \n",
        "        # Computes the initial hidden state from the prompt (seed words).\n",
        "        hidden = None\n",
        "        for ind in seed_words_arr:\n",
        "            data = ind.to(device)\n",
        "            output, hidden = model.inference(data, hidden)\n",
        "\n",
        "        outputs = []\n",
        "        # Initializes the beam list.\n",
        "        beams = [([], output, hidden, 0)]\n",
        "        \n",
        "        for ii in range(sequence_length):\n",
        "            all_beams = list()\n",
        "            # For each beam in the beam list\n",
        "            for i in range(len(beams)):\n",
        "                sequence, output, hidden, score = beams[i]\n",
        "\n",
        "                if (len(sequence) > 0):\n",
        "                    # Compute the next distribution over the output space for that state\n",
        "                    output, hidden = model.inference(sequence[-1], hidden)\n",
        "\n",
        "                # Sample from the distribution    \n",
        "                samples = torch.multinomial(output, BEAM_WIDTH)\n",
        "\n",
        "                # For each sample\n",
        "                for sample in samples[0]:\n",
        "                    # Compute its score and Record its hidden state and chosen value\n",
        "                    beam = (sequence + [sample], output, hidden, score + log(output[0][sample]))\n",
        "                    # Add all the samples to the new beam list\n",
        "                    all_beams.append(beam)\n",
        "\n",
        "            # Rank the new beam list\n",
        "            ordered_beams = sorted(all_beams, key=lambda beam:beam[3], reverse=True)\n",
        "\n",
        "            # Throw out all but the top N beams\n",
        "            beams = ordered_beams[:5]\n",
        "\n",
        "            # Return the top beam's chosen values\n",
        "            outputs = beams[0][0]\n",
        "        \n",
        "        if not use_indices:\n",
        "            return vocab.array_to_words(seed_words_arr.tolist() + outputs)\n",
        "        else:\n",
        "            return seed_words_arr.tolist() + outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGpDwKPhKsR-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "def train(generator, discriminator, device, train_loader, lr, epoch, log_interval, vocab, batch_size, sequence_length):\n",
        "    losses = []\n",
        "    hidden = None\n",
        "    for batch_idx, (data, label) in enumerate(train_loader):\n",
        "        human_data, label = data.to(device), label.to(device)\n",
        "        # Separates the hidden state across batches. \n",
        "        # Otherwise the backward would try to go all the way to the beginning every time.\n",
        "        if hidden is not None:\n",
        "            hidden = repackage_hidden(hidden)\n",
        "        \n",
        "        human_labels = torch.ones(BATCH_SIZE, 1).to(device)\n",
        "        machine_labels = torch.zeros(BATCH_SIZE, 1).to(device)\n",
        "        \n",
        "        # Discriminator training: detect machine input\n",
        "        d_output = discriminator(human_data)\n",
        "        human_loss = discriminator.loss(d_output, human_labels)\n",
        "        \n",
        "        fake_data = []\n",
        "        for batch in range(batch_size):\n",
        "          seed_words_id = torch.multinomial(torch.ones(len(vocab)), num_samples=1).unsqueeze(1)\n",
        "          seed_word = vocab.array_to_words([seed_words_id.item()])\n",
        "          fake_sentence = generate_language(generator, device, seed_word[0], sequence_length - 1, vocab, beam_width=15, use_indices=True)\n",
        "          fake_data.append(fake_sentence)\n",
        "        fake_data = torch.from_numpy(np.array(fake_data)).to(device)\n",
        "        \n",
        "        discriminator.train()\n",
        "        d_output = discriminator(fake_data)\n",
        "        machine_loss = discriminator.loss(d_output, machine_labels)\n",
        "        \n",
        "        discriminator_loss = human_loss + machine_loss\n",
        "        discriminator_optimizer.zero_grad()\n",
        "        generator_optimizer.zero_grad()\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "        \n",
        "        \n",
        "        # Generator training\n",
        "        # Create a different set of data\n",
        "        fake_data = []\n",
        "        for batch in range(batch_size):\n",
        "          seed_words_id = torch.multinomial(torch.ones(len(vocab)), num_samples=1).unsqueeze(1)\n",
        "          seed_word = vocab.array_to_words([seed_words_id.item()])\n",
        "          fake_sentence = generate_language(generator, device, seed_word[0], sequence_length - 1, vocab, beam_width=15, use_indices=True)\n",
        "          fake_data.append(fake_sentence)\n",
        "        fake_data = torch.from_numpy(np.array(fake_data)).to(device)\n",
        "\n",
        "        # Tell discriminator the fake data is real\n",
        "        # How well does discriminator being tricked?\n",
        "        d_output = discriminator(fake_data)\n",
        "        \n",
        "        # Calculate the loss for the discriminator to distinguish between real/fake launguage\n",
        "        trickery_loss = discriminator.loss(d_output, human_labels)\n",
        " \n",
        "        # Calculate the loss for the generators ability to produce meaningful language\n",
        "        generator_optimizer.zero_grad()\n",
        "        generator.train()\n",
        "        output, hidden = generator(human_data, hidden)\n",
        "        pred = output.max(-1)[1]\n",
        "        language_loss = generator.loss(output, label)\n",
        "        \n",
        "        # The loss for the generator is the sum of the loss for tricking and language generation\n",
        "        generator_loss = trickery_loss + language_loss\n",
        "        \n",
        "        losses.append(generator_loss.item())\n",
        "        generator.train()\n",
        "        trickery_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLanguage Loss: {:.6f}\\tTrickery Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), language_loss.item(), trickery_loss.item()))\n",
        "    return np.mean(losses)\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden = None\n",
        "        for batch_idx, (data, label) in enumerate(test_loader):\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output, hidden = model(data, hidden)\n",
        "            test_loss += model.loss(output, label).item()\n",
        "            pred = output.max(-1)[1]\n",
        "            correct_mask = pred.eq(label.view_as(pred))\n",
        "            num_correct = correct_mask.sum().item()\n",
        "            correct += num_correct\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy = 100. * correct / (len(test_loader.dataset) * test_loader.dataset.sequence_length)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset) * test_loader.dataset.sequence_length,\n",
        "        100. * correct / (len(test_loader.dataset) * test_loader.dataset.sequence_length)))\n",
        "    return test_loss, test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SPVeA4emLk3V",
        "colab_type": "code",
        "outputId": "a9ad49fe-22bb-46b6-fd70-9ef12e34c2b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13146
        }
      },
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 50\n",
        "BATCH_SIZE = 2\n",
        "EMBED_SIZE = 1024\n",
        "FEATURE_SIZE = 1024\n",
        "TEST_BATCH_SIZE = 10\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.0005\n",
        "USE_CUDA = True\n",
        "PRINT_INTERVAL = 10\n",
        "LOG_PATH = DATA_PATH + 'logs/log.pkl'\n",
        "NUM_LAYERS = 2\n",
        "!export CUDA_LAUNCH_BLOCKING=1; \n",
        "\n",
        "data_train = ReviewsDataset(DATA_PATH + 'office_products_chars_train.pkl', SEQUENCE_LENGTH, BATCH_SIZE)\n",
        "data_test = ReviewsDataset(DATA_PATH + 'office_products_chars_test.pkl', SEQUENCE_LENGTH, TEST_BATCH_SIZE)\n",
        "vocab = data_train.vocab\n",
        "\n",
        "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "import multiprocessing\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "print('num workers:', num_workers)\n",
        "\n",
        "kwargs = {'num_workers': num_workers,\n",
        "          'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE,\n",
        "                                           shuffle=False, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=TEST_BATCH_SIZE,\n",
        "                                          shuffle=False, **kwargs)\n",
        "\n",
        "generator = Generator(data_train.vocab_size(), EMBED_SIZE, FEATURE_SIZE, NUM_LAYERS).to(device)\n",
        "discriminator = Discriminator(data_train.vocab_size(), EMBED_SIZE, FEATURE_SIZE, BATCH_SIZE, SEQUENCE_LENGTH).to(device)\n",
        "\n",
        "generator_optimizer = optim.Adam(generator.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "start_epoch = generator.load_last_model(DATA_PATH + 'checkpoints')\n",
        "\n",
        "train_losses, test_losses, test_accuracies, train_p, test_p = pt_util.read_log(LOG_PATH, ([], [], [], [], []))\n",
        "test_loss, test_accuracy = test(generator, device, test_loader)\n",
        "\n",
        "test_losses.append((start_epoch, test_loss))\n",
        "test_accuracies.append((start_epoch, test_accuracy))\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, EPOCHS + 1):\n",
        "        lr = LEARNING_RATE * np.power(0.25, (int(epoch / 6)))\n",
        "        train_loss = train(generator, discriminator, device, train_loader, lr, epoch, PRINT_INTERVAL, vocab, BATCH_SIZE, SEQUENCE_LENGTH)\n",
        "        test_loss, test_accuracy = test(generator, device, test_loader)\n",
        "        train_losses.append((epoch, train_loss))\n",
        "        test_losses.append((epoch, test_loss))\n",
        "        test_accuracies.append((epoch, test_accuracy))\n",
        "        test_p.append((epoch, exp(test_loss)))\n",
        "        train_p.append((epoch, exp(train_loss)))\n",
        "        pt_util.write_log(LOG_PATH, (train_losses, test_losses, test_accuracies, train_p, test_p))\n",
        "        generator.save_best_model(test_accuracy, DATA_PATH + 'checkpoints/%03d.pt' % epoch)\n",
        "        seed_words = 'This printer quality is'\n",
        "        generated_sentence = generate_language(generator, device, seed_words, 200, vocab)\n",
        "        print('generated beam\\t\\t', generated_sentence)\n",
        "        print('')\n",
        "\n",
        "except KeyboardInterrupt as ke:\n",
        "    print('Interrupted')\n",
        "except:\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    print('Saving final model')\n",
        "    generator.save_model(DATA_PATH + 'checkpoints/%03d.pt' % epoch, 0)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "num workers: 2\n",
            "Restoring:\n",
            "encoder.weight -> \ttorch.Size([92, 1024]) = 0MB\n",
            "lstm.weight_ih_l0 -> \ttorch.Size([4096, 1024]) = 16MB\n",
            "lstm.weight_hh_l0 -> \ttorch.Size([4096, 1024]) = 16MB\n",
            "lstm.bias_ih_l0 -> \ttorch.Size([4096]) = 0MB\n",
            "lstm.bias_hh_l0 -> \ttorch.Size([4096]) = 0MB\n",
            "lstm.weight_ih_l1 -> \ttorch.Size([4096, 1024]) = 16MB\n",
            "lstm.weight_hh_l1 -> \ttorch.Size([4096, 1024]) = 16MB\n",
            "lstm.bias_ih_l1 -> \ttorch.Size([4096]) = 0MB\n",
            "lstm.bias_hh_l1 -> \ttorch.Size([4096]) = 0MB\n",
            "decoder.weight -> \ttorch.Size([92, 1024]) = 0MB\n",
            "decoder.bias -> \ttorch.Size([92]) = 0MB\n",
            "\n",
            "Restored all variables\n",
            "No new variables\n",
            "Restored /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n",
            "Test set: Average loss: 2.6030, Accuracy: 480653/1708500 (28%)\n",
            "\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [0/136706 (0%)]\tLanguage Loss: 2.246804\tTrickery Loss: 2.181214\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [20/136706 (0%)]\tLanguage Loss: 2.338284\tTrickery Loss: 4.590195\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [40/136706 (0%)]\tLanguage Loss: 2.052758\tTrickery Loss: 30.962194\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [60/136706 (0%)]\tLanguage Loss: 2.179374\tTrickery Loss: 21.484240\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [80/136706 (0%)]\tLanguage Loss: 2.210105\tTrickery Loss: 9.573364\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [100/136706 (0%)]\tLanguage Loss: 2.489737\tTrickery Loss: 38.833580\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [120/136706 (0%)]\tLanguage Loss: 2.164624\tTrickery Loss: 34.672039\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [140/136706 (0%)]\tLanguage Loss: 2.421874\tTrickery Loss: 21.292965\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [160/136706 (0%)]\tLanguage Loss: 3.975249\tTrickery Loss: 60.414345\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [180/136706 (0%)]\tLanguage Loss: 3.387046\tTrickery Loss: 48.589485\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [200/136706 (0%)]\tLanguage Loss: 2.324061\tTrickery Loss: 46.723091\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [220/136706 (0%)]\tLanguage Loss: 2.605187\tTrickery Loss: 47.993984\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [240/136706 (0%)]\tLanguage Loss: 2.467072\tTrickery Loss: 24.561888\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [260/136706 (0%)]\tLanguage Loss: 2.458614\tTrickery Loss: 25.083086\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [280/136706 (0%)]\tLanguage Loss: 2.347232\tTrickery Loss: 19.582298\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [300/136706 (0%)]\tLanguage Loss: 2.936398\tTrickery Loss: 50.139942\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [320/136706 (0%)]\tLanguage Loss: 2.677895\tTrickery Loss: 32.281773\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [340/136706 (0%)]\tLanguage Loss: 2.635246\tTrickery Loss: 41.419666\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [360/136706 (0%)]\tLanguage Loss: 2.705478\tTrickery Loss: 19.591820\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [380/136706 (0%)]\tLanguage Loss: 2.530851\tTrickery Loss: 31.776325\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [400/136706 (0%)]\tLanguage Loss: 2.761189\tTrickery Loss: 21.054688\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [420/136706 (0%)]\tLanguage Loss: 2.442464\tTrickery Loss: 17.833023\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "Train Epoch: 0 [440/136706 (0%)]\tLanguage Loss: 2.419545\tTrickery Loss: 19.372591\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n",
            "torch.Size([2, 50, 1024])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-66:\n",
            "Process Process-65:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Interrupted\n",
            "Saving final model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
            "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n",
            "    fd_event_list = self._poll.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
            "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n",
            "    fd_event_list = self._poll.poll(timeout)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved /gdrive/My Drive/colab_files/fake_review_generator/fake_review_generator/checkpoints/000.pt\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dblC_7gtLT1S",
        "colab_type": "code",
        "outputId": "81b902ec-d7f8-4659-bf28-ba8a8d47422f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1209
        }
      },
      "cell_type": "code",
      "source": [
        "seed_words = 'This printer is'\n",
        "sequence_length = 100\n",
        "\n",
        "for ii in range(10):\n",
        "    generated_sentence = generate_language(generator, device, seed_words, sequence_length, vocab)\n",
        "    print('generated with beam\\t', generated_sentence)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generated with beam\t This printer isw>>cccccwccccScwcccSSS^^>^cccScwSScSSSjVVVVn$$qkq`kWWu5CcccwSSSSVVM>Mfff:::pxJ,,$99ttP::tJtxqJ,',S9S\n",
            "generated with beam\t This printer is+x>vccw'cc'ccc/SwSSS^^^^^cccccwScM_S>SSjVjVV>nccccwcccccwScccwSSS>j>ccccccwScccccwSS>cccSccwccSwS>cc\n",
            "generated with beam\t This printer is>cwcccccwcccc/SwS>cccc/SwcSSSVVMMMff:f::t:tJq,,,99S/RwmSS2SVMVMfP:::t$qI:#Iccwcccc/wSS>>ccccccwcccSS\n",
            "generated with beam\t This printer isccw_cccc/wSSMS>>ccccwccccccwS_S>>cccccccSwSSSVMMff:::ttJJuuuDz#sx>>ccccwccc'ccwccSSwS>ccccScSwSS>jjV\n",
            "generated with beam\t This printer is4+>cccccwcccccwcSccwccwSMSS>1cccccwSS_S>ccScSSSVV>>cccccSSwSS>>ccccwScSSSVVM$$qq`k5k,k,,,SSSjVVVV7n7\n",
            "generated with beam\t This printer isx>>ccccwcccScwSS>cccccwccccccwcSSSMjVVV7~V~~VVL~~Vk~~~kk~~k~k~~kk~~kk~kkkWWuugFL$jVn;;,,SSSSVjVV>7nn\n",
            "generated with beam\t This printer ist*>c>cccwcc'ccc/wSSS>jjVV>cccwcccccwSSSjVV VMfM:f:::tttJJuuezss>>ccccccwccccwccccSwS>cccccccwSS>cMcw\n",
            "generated with beam\t This printer is>cc_ccSwSSSVjVVM$7}jVV?n,,,,,SSSS^S^^^^WcccwccSSSjVVV77~~V~~VVnn;;;>>22cccwSccSSSMjVV7V77cccccSwS>cc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-15cb339054e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgenerated_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generated with beam\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-65f4a997c18e>\u001b[0m in \u001b[0;36mgenerate_language\u001b[0;34m(model, device, seed_words, sequence_length, vocab, beam_width, use_indices)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_words_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0e2b1e8e4cd6>\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, x, hidden_state, temperature)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0e2b1e8e4cd6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Forward propagate LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Reshape output to (batch_size*sequence_length, feature_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}